{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2987387a",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d820d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f5908",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "## Loading the genre label of each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf06518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        track_id music_genre                      path\n",
      "0              2     Hip-Hop  fma_small/000/000002.mp3\n",
      "1              3     Hip-Hop  fma_small/000/000003.mp3\n",
      "2              5     Hip-Hop  fma_small/000/000005.mp3\n",
      "3             10         Pop  fma_small/000/000010.mp3\n",
      "4             20         NaN  fma_small/000/000020.mp3\n",
      "...          ...         ...                       ...\n",
      "106569    155316        Rock  fma_small/155/155316.mp3\n",
      "106570    155317        Rock  fma_small/155/155317.mp3\n",
      "106571    155318        Rock  fma_small/155/155318.mp3\n",
      "106572    155319        Rock  fma_small/155/155319.mp3\n",
      "106573    155320         NaN  fma_small/155/155320.mp3\n",
      "\n",
      "[106574 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading the information about each track (metadata)\n",
    "path_of_fma_metadata = \"../fma_metadata/tracks.csv\"\n",
    "fma_metadata = pd.read_csv(path_of_fma_metadata, header=[0, 1], index_col=0)\n",
    "# Flatten columns multi-index\n",
    "fma_metadata.columns = ['__'.join(col).strip() for col in fma_metadata.columns.values]\n",
    "\n",
    "# Keeping only the genre column\n",
    "track_genre_df = fma_metadata.reset_index()[['track_id', 'track__genre_top']]\n",
    "track_genre_df = track_genre_df.rename(columns={\"track__genre_top\": \"music_genre\"})\n",
    "\n",
    "# Function to get the audio file path from track_id\n",
    "def get_audio_path(track_id):\n",
    "    # There are 1000 tracks per folder\n",
    "    folder = str(track_id // 1000).zfill(3)\n",
    "    filename = f\"{str(track_id).zfill(6)}.mp3\"\n",
    "    return \"fma_small\" + f\"/{folder}/{filename}\"\n",
    "\n",
    "track_genre_df[\"path\"] = track_genre_df[\"track_id\"].apply(get_audio_path)\n",
    "print(track_genre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad9991b",
   "metadata": {},
   "source": [
    "## Preprocessing the data with Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1937f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, track_genre_df, transform=None):\n",
    "        self.track_genre_df = track_genre_df\n",
    "        self.transform = transform\n",
    "        self.genre_to_idx = {genre: idx for idx, genre in enumerate(track_genre_df['music_genre'].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.track_genre_df)\n",
    "    \n",
    "    # Methods \n",
    "    # Loading the audio file\n",
    "    def load_audio(path):\n",
    "        audio, _ = librosa.load(path, mono=True)\n",
    "        return audio\n",
    "\n",
    "    # Converting audio to mel-spectrogram\n",
    "    def audio_to_mel(audio):\n",
    "        mel = librosa.feature.melspectrogram(y=audio,n_mels=128)\n",
    "        mel_db = librosa.power_to_db(mel)\n",
    "        return mel_db.astype(np.float32)\n",
    "\n",
    "    # Normalizing the mel-spectrogram per track\n",
    "    def track_normalization(mel):\n",
    "        mean = mel.mean()\n",
    "        std = mel.std()\n",
    "        if std < 1e-6:\n",
    "            std = 1.0\n",
    "        return (mel - mean) / std\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.track_genre_df.iloc[idx]\n",
    "        audio_path = row['path']\n",
    "        genre = row['music_genre']\n",
    "        genre_idx = self.genre_to_idx[genre]\n",
    "\n",
    "        # Load audio and convert to mel-spectrogram\n",
    "        audio = self.load_audio(audio_path)\n",
    "        mel = self.audio_to_mel(audio)\n",
    "        mel_normalized = self.track_normalization(mel)\n",
    "\n",
    "        if self.transform:\n",
    "            mel_normalized = self.transform(mel_normalized)\n",
    "\n",
    "        return mel_normalized, genre_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423471db",
   "metadata": {},
   "source": [
    "# Baseline Implementation\n",
    "## Model : \n",
    "Small (2D) CNN with 3 convolutional layers (Conv → ReLU → MaxPool →\n",
    "Dropout), followed by a fully connected layer and softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593b129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our baseline model\n",
    "class CNN_base(nn.Module):\n",
    "    def __init__(self, num_classes=8, dropout=0.25):\n",
    "        super().__init__()\n",
    "        channels = [1, 32, 64, 128]\n",
    "        layers = []\n",
    "        for i in range(3):\n",
    "            layers += [\n",
    "                nn.Conv2d(channels[i], channels[i + 1], kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout2d(dropout)\n",
    "            ]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47289d9",
   "metadata": {},
   "source": [
    " • Loss: Cross-entropy.\n",
    "\n",
    " • Optimizer: Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94424233",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_base(num_classes=8, dropout=0.25)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5851f5f8",
   "metadata": {},
   "source": [
    " • Metric: Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dl, device, writer=None, global_step=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_dl:\n",
    "            mel = mel.to(device)\n",
    "            label = label.to(device)\n",
    "            preds = model(mel).argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    if writer is not None and global_step is not None:\n",
    "        writer.add_scalar(\"test/accuracy\", 100 * correct / total, global_step)\n",
    "    print(f\"Test accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
